{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hHPHxqaOU2OG"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from typing import List, Tuple\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, roc_auc_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (\n",
        "    Input, Dense, LSTM, Attention, Conv1D, MaxPooling1D,\n",
        "    Dropout, Flatten, RepeatVector, TimeDistributed, GaussianNoise, BatchNormalization\n",
        ")\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load datasets\n",
        "\n",
        "df_0 = pd.read_csv(\"Asset_0.csv\")\n",
        "df_11 = pd.read_csv(\"Asset_11.csv\")\n",
        "\n",
        "\n",
        "# Merge datasets\n",
        "df_combined = pd.concat([df_0, df_11], ignore_index=True)\n",
        "\n",
        "\n",
        "# Save combined file\n",
        "df_combined.to_csv(\"combined_data_nndl.csv\", index=False)\n",
        "\n",
        "\n",
        "print(\"Combined dataset shape:\", df_combined.shape)\n",
        "\n",
        "df_combined"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "0w5G03zCV4v7",
        "outputId": "0d862fba-6d9c-48ce-b357-95006eabc065"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset shape: (109240, 86)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              time_stamp  asset_id     id  train_test  status_type_id  \\\n",
              "0       22-05-2022 06:50         0  41807       train               0   \n",
              "1       22-05-2022 07:00         0  41808       train               0   \n",
              "2       22-05-2022 07:10         0  41809       train               0   \n",
              "3       22-05-2022 07:20         0  41810       train               0   \n",
              "4       22-05-2022 07:30         0  41811       train               0   \n",
              "...                  ...       ...    ...         ...             ...   \n",
              "109235  08-06-2023 01:50        11  54707  prediction               0   \n",
              "109236  08-06-2023 02:00        11  54708  prediction               0   \n",
              "109237  08-06-2023 02:10        11  54709  prediction               0   \n",
              "109238  08-06-2023 02:20        11  54710  prediction               0   \n",
              "109239  08-06-2023 02:30        11  54711  prediction               0   \n",
              "\n",
              "        sensor_0_avg  sensor_1_avg  sensor_2_avg  wind_speed_3_avg  \\\n",
              "0                 21          85.5          -4.2               7.4   \n",
              "1                 20          87.8           6.1               7.8   \n",
              "2                 20          92.9           3.6               8.9   \n",
              "3                 20          96.9           7.5               8.8   \n",
              "4                 20          83.4          -5.9               8.6   \n",
              "...              ...           ...           ...               ...   \n",
              "109235            23          97.8         -12.3               7.0   \n",
              "109236            23         123.1          12.9               5.9   \n",
              "109237            23         112.0           1.8               6.5   \n",
              "109238            23         108.7          -1.5               5.0   \n",
              "109239            23         103.5          -8.8               4.3   \n",
              "\n",
              "        wind_speed_4_avg  ...  sensor_47  sensor_48  sensor_49  sensor_50  \\\n",
              "0                    7.5  ...          0     -26917          0     125146   \n",
              "1                    7.8  ...          0     -26741          0     133455   \n",
              "2                    8.9  ...          0     -28905          0     200224   \n",
              "3                    8.8  ...          0     -27062          0     196367   \n",
              "4                    8.5  ...          0     -26566          0     176781   \n",
              "...                  ...  ...        ...        ...        ...        ...   \n",
              "109235               6.8  ...          0     -19262          0      89874   \n",
              "109236               5.8  ...          0     -16961          0      51700   \n",
              "109237               6.3  ...          0     -17394          0      70296   \n",
              "109238               4.8  ...          0     -14145          0      28987   \n",
              "109239               4.1  ...          0      -3617          0      11511   \n",
              "\n",
              "        sensor_51  sensor_52_avg  sensor_52_max  sensor_52_min  sensor_52_std  \\\n",
              "0          -26917           13.5           14.8           11.4            1.0   \n",
              "1          -26741           14.1           14.7           13.1            0.3   \n",
              "2          -28905           14.6           14.9           13.8            0.2   \n",
              "3          -27062           14.6           14.9           14.0            0.1   \n",
              "4          -26566           14.5           14.8           13.9            0.2   \n",
              "...           ...            ...            ...            ...            ...   \n",
              "109235     -19262           13.1           14.9           11.1            1.1   \n",
              "109236     -16961           11.9           13.5           10.9            0.6   \n",
              "109237     -17394           12.6           14.2           11.0            0.8   \n",
              "109238     -14145           11.5           13.5           10.9            0.7   \n",
              "109239      -3617           11.1           11.4           10.9            0.1   \n",
              "\n",
              "        sensor_53_avg  \n",
              "0                  22  \n",
              "1                  22  \n",
              "2                  22  \n",
              "3                  22  \n",
              "4                  22  \n",
              "...               ...  \n",
              "109235             23  \n",
              "109236             23  \n",
              "109237             23  \n",
              "109238             23  \n",
              "109239             23  \n",
              "\n",
              "[109240 rows x 86 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e83b038-8cba-4646-9ee7-f749d4e544e0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time_stamp</th>\n",
              "      <th>asset_id</th>\n",
              "      <th>id</th>\n",
              "      <th>train_test</th>\n",
              "      <th>status_type_id</th>\n",
              "      <th>sensor_0_avg</th>\n",
              "      <th>sensor_1_avg</th>\n",
              "      <th>sensor_2_avg</th>\n",
              "      <th>wind_speed_3_avg</th>\n",
              "      <th>wind_speed_4_avg</th>\n",
              "      <th>...</th>\n",
              "      <th>sensor_47</th>\n",
              "      <th>sensor_48</th>\n",
              "      <th>sensor_49</th>\n",
              "      <th>sensor_50</th>\n",
              "      <th>sensor_51</th>\n",
              "      <th>sensor_52_avg</th>\n",
              "      <th>sensor_52_max</th>\n",
              "      <th>sensor_52_min</th>\n",
              "      <th>sensor_52_std</th>\n",
              "      <th>sensor_53_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22-05-2022 06:50</td>\n",
              "      <td>0</td>\n",
              "      <td>41807</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>85.5</td>\n",
              "      <td>-4.2</td>\n",
              "      <td>7.4</td>\n",
              "      <td>7.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-26917</td>\n",
              "      <td>0</td>\n",
              "      <td>125146</td>\n",
              "      <td>-26917</td>\n",
              "      <td>13.5</td>\n",
              "      <td>14.8</td>\n",
              "      <td>11.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22-05-2022 07:00</td>\n",
              "      <td>0</td>\n",
              "      <td>41808</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>87.8</td>\n",
              "      <td>6.1</td>\n",
              "      <td>7.8</td>\n",
              "      <td>7.8</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-26741</td>\n",
              "      <td>0</td>\n",
              "      <td>133455</td>\n",
              "      <td>-26741</td>\n",
              "      <td>14.1</td>\n",
              "      <td>14.7</td>\n",
              "      <td>13.1</td>\n",
              "      <td>0.3</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22-05-2022 07:10</td>\n",
              "      <td>0</td>\n",
              "      <td>41809</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>92.9</td>\n",
              "      <td>3.6</td>\n",
              "      <td>8.9</td>\n",
              "      <td>8.9</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-28905</td>\n",
              "      <td>0</td>\n",
              "      <td>200224</td>\n",
              "      <td>-28905</td>\n",
              "      <td>14.6</td>\n",
              "      <td>14.9</td>\n",
              "      <td>13.8</td>\n",
              "      <td>0.2</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22-05-2022 07:20</td>\n",
              "      <td>0</td>\n",
              "      <td>41810</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>96.9</td>\n",
              "      <td>7.5</td>\n",
              "      <td>8.8</td>\n",
              "      <td>8.8</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-27062</td>\n",
              "      <td>0</td>\n",
              "      <td>196367</td>\n",
              "      <td>-27062</td>\n",
              "      <td>14.6</td>\n",
              "      <td>14.9</td>\n",
              "      <td>14.0</td>\n",
              "      <td>0.1</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22-05-2022 07:30</td>\n",
              "      <td>0</td>\n",
              "      <td>41811</td>\n",
              "      <td>train</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>83.4</td>\n",
              "      <td>-5.9</td>\n",
              "      <td>8.6</td>\n",
              "      <td>8.5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-26566</td>\n",
              "      <td>0</td>\n",
              "      <td>176781</td>\n",
              "      <td>-26566</td>\n",
              "      <td>14.5</td>\n",
              "      <td>14.8</td>\n",
              "      <td>13.9</td>\n",
              "      <td>0.2</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109235</th>\n",
              "      <td>08-06-2023 01:50</td>\n",
              "      <td>11</td>\n",
              "      <td>54707</td>\n",
              "      <td>prediction</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>97.8</td>\n",
              "      <td>-12.3</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6.8</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-19262</td>\n",
              "      <td>0</td>\n",
              "      <td>89874</td>\n",
              "      <td>-19262</td>\n",
              "      <td>13.1</td>\n",
              "      <td>14.9</td>\n",
              "      <td>11.1</td>\n",
              "      <td>1.1</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109236</th>\n",
              "      <td>08-06-2023 02:00</td>\n",
              "      <td>11</td>\n",
              "      <td>54708</td>\n",
              "      <td>prediction</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>123.1</td>\n",
              "      <td>12.9</td>\n",
              "      <td>5.9</td>\n",
              "      <td>5.8</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-16961</td>\n",
              "      <td>0</td>\n",
              "      <td>51700</td>\n",
              "      <td>-16961</td>\n",
              "      <td>11.9</td>\n",
              "      <td>13.5</td>\n",
              "      <td>10.9</td>\n",
              "      <td>0.6</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109237</th>\n",
              "      <td>08-06-2023 02:10</td>\n",
              "      <td>11</td>\n",
              "      <td>54709</td>\n",
              "      <td>prediction</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>112.0</td>\n",
              "      <td>1.8</td>\n",
              "      <td>6.5</td>\n",
              "      <td>6.3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-17394</td>\n",
              "      <td>0</td>\n",
              "      <td>70296</td>\n",
              "      <td>-17394</td>\n",
              "      <td>12.6</td>\n",
              "      <td>14.2</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109238</th>\n",
              "      <td>08-06-2023 02:20</td>\n",
              "      <td>11</td>\n",
              "      <td>54710</td>\n",
              "      <td>prediction</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>108.7</td>\n",
              "      <td>-1.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-14145</td>\n",
              "      <td>0</td>\n",
              "      <td>28987</td>\n",
              "      <td>-14145</td>\n",
              "      <td>11.5</td>\n",
              "      <td>13.5</td>\n",
              "      <td>10.9</td>\n",
              "      <td>0.7</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109239</th>\n",
              "      <td>08-06-2023 02:30</td>\n",
              "      <td>11</td>\n",
              "      <td>54711</td>\n",
              "      <td>prediction</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>103.5</td>\n",
              "      <td>-8.8</td>\n",
              "      <td>4.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>-3617</td>\n",
              "      <td>0</td>\n",
              "      <td>11511</td>\n",
              "      <td>-3617</td>\n",
              "      <td>11.1</td>\n",
              "      <td>11.4</td>\n",
              "      <td>10.9</td>\n",
              "      <td>0.1</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>109240 rows Ã— 86 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e83b038-8cba-4646-9ee7-f749d4e544e0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2e83b038-8cba-4646-9ee7-f749d4e544e0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2e83b038-8cba-4646-9ee7-f749d4e544e0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-94684ef1-bc84-4969-b4fe-630d6a934565\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-94684ef1-bc84-4969-b4fe-630d6a934565')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-94684ef1-bc84-4969-b4fe-630d6a934565 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f5473945-40c3-49fe-8fab-47dc6aee444c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_combined')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f5473945-40c3-49fe-8fab-47dc6aee444c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_combined');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_combined"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DATA PREPROCESSING\n",
        "\n",
        "# Helper functions for preprocessing and sequence-building\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 5)\n",
        "\n",
        "META_COLS = ['time_stamp', 'asset_id', 'id', 'train_test']\n",
        "TARGET_COL = 'status_type_id'\n",
        "\n",
        "# select only numeric features\n",
        "# excluding metadata columns and the target label\n",
        "def numeric_feature_cols(df: pd.DataFrame) -> List[str]:\n",
        "    cols = []\n",
        "    for c in df.columns:\n",
        "        if c in META_COLS or c == TARGET_COL:\n",
        "            continue\n",
        "        if pd.api.types.is_numeric_dtype(df[c]):\n",
        "            cols.append(c)\n",
        "    return cols\n",
        "\n",
        "#missing value imputation (forward and backward fill)\n",
        "def robust_fillna_per_asset(df: pd.DataFrame, feature_cols: List[str]) -> pd.DataFrame:\n",
        "    if 'asset_id' in df.columns:\n",
        "        df[feature_cols] = (df.groupby('asset_id')[feature_cols]\n",
        "                              .apply(lambda g: g.ffill().bfill())\n",
        "                              .reset_index(level=0, drop=True))\n",
        "    else:\n",
        "        df[feature_cols] = df[feature_cols].ffill().bfill()\n",
        "    return df\n",
        "\n",
        "# clip outliers\n",
        "#uses percentile-based clipping\n",
        "def clip_outliers(df: pd.DataFrame, feature_cols: List[str], lower_q=0.005, upper_q=0.995) -> pd.DataFrame:\n",
        "    for c in feature_cols:\n",
        "        s = df[c].astype(float)\n",
        "        lo = s.quantile(lower_q)\n",
        "        hi = s.quantile(upper_q)\n",
        "        df[c] = s.clip(lo, hi)\n",
        "    return df\n",
        "\n",
        "#FEATURE ENGINEERING (DIFFERENCE + ROLLING MEAN)\n",
        "def add_engineered_features(df: pd.DataFrame, feature_cols: List[str]) -> Tuple[pd.DataFrame, List[str]]:\n",
        "\n",
        "    # Adds first difference and rolling-3 mean per asset\n",
        "\n",
        "    new_cols = []\n",
        "\n",
        "    #asset-specific processing\n",
        "    if 'asset_id' in df.columns:\n",
        "        grp = df.groupby('asset_id')\n",
        "        for c in feature_cols:\n",
        "            d1 = f'd1_{c}'\n",
        "            r3 = f'r3m_{c}'\n",
        "            df[d1] = grp[c].diff().fillna(0.0)\n",
        "            df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
        "            new_cols += [d1, r3]\n",
        "\n",
        "    # no asset separation available\n",
        "    else:\n",
        "        for c in feature_cols:\n",
        "            d1 = f'd1_{c}'\n",
        "            r3 = f'r3m_{c}'\n",
        "            df[d1] = df[c].diff().fillna(0.0)\n",
        "            df[r3] = df[c].rolling(3, min_periods=1).mean()\n",
        "            new_cols += [d1, r3]\n",
        "\n",
        "    # Combine original + engineered features\n",
        "    all_features = feature_cols + new_cols\n",
        "    return df, all_features\n",
        "\n",
        "\n",
        "# standard scaling\n",
        "def scale_features(df: pd.DataFrame, feature_cols: List[str]) -> Tuple[np.ndarray, StandardScaler]:\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(df[feature_cols].astype(float).values)\n",
        "    return X, scaler\n",
        "\n",
        "\n",
        "#LSTM SEQUENCE GENERATION\n",
        "#Build sliding windows per asset so windows don't cross asset boundaries.\n",
        "\n",
        "def build_sequences_asset_safe(X: np.ndarray, y: np.ndarray, asset_ids: np.ndarray, seq_len: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "\n",
        "    #Label each window as 1 if ANY row in the window has status_type_id > 0, else 0.\n",
        "\n",
        "    X_seqs, y_seqs = [], []\n",
        "\n",
        "    # No asset_id grouping -> single global sequence\n",
        "    if asset_ids is None:\n",
        "        idx = np.arange(len(y))\n",
        "        for i in range(0, len(idx) - seq_len + 1):\n",
        "            sl = idx[i:i+seq_len]\n",
        "            X_seqs.append(X[sl, :])\n",
        "            y_seqs.append(int(np.max(y[sl]) > 0))\n",
        "\n",
        "    # Build sequences separately for every asset\n",
        "    else:\n",
        "        for aid in pd.unique(asset_ids):\n",
        "            mask = (asset_ids == aid)\n",
        "            idx = np.where(mask)[0]\n",
        "\n",
        "            for i in range(0, len(idx) - seq_len + 1):\n",
        "                sl = idx[i:i+seq_len]\n",
        "                X_seqs.append(X[sl, :])\n",
        "                y_seqs.append(int(np.max(y[sl]) > 0))\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_seqs = np.stack(X_seqs, axis=0) if len(X_seqs) else np.empty((0, seq_len, X.shape[1]))\n",
        "    y_seqs = np.array(y_seqs, dtype=int)\n",
        "    return X_seqs, y_seqs\n"
      ],
      "metadata": {
        "id": "WM9mE627WIsd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREPROCESSINF PIPELINE\n",
        "\n",
        "# 1. ensuring df_combined exists\n",
        "assert 'df_combined' in globals() or 'df_combined' in locals(), \"df_combined not found. Assign your combined dataset to df_combined.\"\n",
        "\n",
        "\n",
        "# 2. Sort by aasset_id and time_stamp\n",
        "\n",
        "if 'asset_id' in df_combined.columns and 'time_stamp' in df_combined.columns:\n",
        "    try:\n",
        "        # Convert timestamp to proper datetime format\n",
        "        df_combined['time_stamp'] = pd.to_datetime(df_combined['time_stamp'])\n",
        "        df_combined = df_combined.sort_values(['asset_id', 'time_stamp']).reset_index(drop=True)\n",
        "\n",
        "    except Exception:\n",
        "        # to avoid breaking the pipeline if timestamp column has invalid formats,\n",
        "        df_combined = df_combined.reset_index(drop=True)\n",
        "else:\n",
        "    # If one of the columns is missing, ensure clean index\n",
        "    df_combined = df_combined.reset_index(drop=True)\n",
        "\n",
        "\n",
        "# 3. Drop rows with missing target\n",
        "df_combined = df_combined[df_combined[TARGET_COL].notna()].reset_index(drop=True)\n",
        "\n",
        "\n",
        "# 4. Select numeric features. Exclude metadata\n",
        "base_feature_cols = numeric_feature_cols(df_combined)\n",
        "print(\"Initial numeric features count:\", len(base_feature_cols))\n",
        "\n",
        "\n",
        "# 5. Fill NaNs per asset and clip outliers\n",
        "df_combined = robust_fillna_per_asset(df_combined, base_feature_cols)\n",
        "df_combined = clip_outliers(df_combined, base_feature_cols, lower_q=0.005, upper_q=0.995)\n",
        "\n",
        "# 6. Feature engineering (d1, rolling3)\n",
        "df_combined, feature_cols = add_engineered_features(df_combined, base_feature_cols)\n",
        "print(\"Final feature count after engineering:\", len(feature_cols))\n",
        "\n",
        "# 7. Scaling\n",
        "X_all, scaler = scale_features(df_combined, feature_cols)\n",
        "\n",
        "# Prepare the target variable\n",
        "y_all = df_combined[TARGET_COL].astype(int).values\n",
        "\n",
        "# extract asset IDs (if present) for per-asset sequence building\n",
        "asset_ids = df_combined['asset_id'].values if 'asset_id' in df_combined.columns else None\n",
        "\n",
        "print(\"X_all shape:\", X_all.shape, \"y_all shape:\", y_all.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_kOLF8tgfSYh",
        "outputId": "99a20b71-bbdf-4b8b-f6c5-5609b4a990b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1758747193.py:12: UserWarning: Parsing dates in %d-%m-%Y %H:%M format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  df_combined['time_stamp'] = pd.to_datetime(df_combined['time_stamp'])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial numeric features count: 81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n",
            "/tmp/ipython-input-2226473069.py:59: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[d1] = grp[c].diff().fillna(0.0)\n",
            "/tmp/ipython-input-2226473069.py:60: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df[r3] = grp[c].transform(lambda s: s.rolling(3, min_periods=1).mean())\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final feature count after engineering: 243\n",
            "X_all shape: (109240, 243) y_all shape: (109240,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences\n",
        "\n",
        "SEQUENCE_LENGTH = 10\n",
        "\n",
        "# Build sliding windows per asset without crossing boundaries\n",
        "X_seq, y_seq = build_sequences_asset_safe(X_all, y_all, asset_ids, SEQUENCE_LENGTH)\n",
        "\n",
        "print(\"Sequence dataset shape:\", X_seq.shape, y_seq.shape)\n",
        "print(\"Sequence-level positive (fault) rate:\", y_seq.mean())\n",
        "\n",
        "#Define split proportions\n",
        "test_size = 0.2\n",
        "val_size = 0.2\n",
        "\n",
        "# Check class distribution (0 = normal, 1 = fault)\n",
        "unique, counts = np.unique(y_seq, return_counts=True)\n",
        "print(\"Sequence label distribution:\", dict(zip(unique, counts)))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "If enough positives exist, use stratified splitting\n",
        "Otherwise â†’ fallback to random split\n",
        "\n",
        "\"\"\"\n",
        "if len(counts) > 1 and np.min(counts) >= 5:\n",
        "    X_tmp, X_test, y_tmp, y_test = train_test_split(\n",
        "        X_seq,\n",
        "        y_seq,\n",
        "        test_size=test_size,\n",
        "        random_state=RANDOM_STATE,\n",
        "        stratify=y_seq\n",
        "    )\n",
        "\n",
        "    # Now split remaining into train pool & validation\n",
        "    X_train_pool, X_val_mixed, y_train_pool, y_val_mixed = train_test_split(\n",
        "        X_tmp,\n",
        "        y_tmp,\n",
        "        test_size=val_size,\n",
        "        random_state=RANDOM_STATE,\n",
        "        stratify=y_tmp\n",
        "\n",
        "    )\n",
        "\n",
        "else:\n",
        "    # fallback to random splits if not enough positives for stratify\n",
        "    X_tmp, X_test, y_tmp, y_test = train_test_split(\n",
        "        X_seq,\n",
        "        y_seq,\n",
        "        test_size=test_size,\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "    X_train_pool, X_val_mixed, y_train_pool, y_val_mixed = train_test_split(\n",
        "        X_tmp,\n",
        "        y_tmp,\n",
        "        test_size=val_size,\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "\n",
        "\n",
        "# Training on normal windows only\n",
        "X_train_norm = X_train_pool[y_train_pool == 0]\n",
        "X_val_norm = X_val_mixed[y_val_mixed == 0]\n",
        "\n",
        "\n",
        "# If no normals in val_norm, carve out 10% from train_norm\n",
        "if len(X_val_norm) == 0 and len(X_train_norm) > 10:\n",
        "    split = int(0.9 * len(X_train_norm))\n",
        "    X_val_norm = X_train_norm[split:]\n",
        "    X_train_norm = X_train_norm[:split]\n",
        "\n",
        "print(\"Train normals:\", X_train_norm.shape,\n",
        "      \"Val normals:\", X_val_norm.shape,\n",
        "      \"Test (mixed):\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSy0Y_h9XZ8k",
        "outputId": "45c4a9f3-8887-4766-d221-7abd168e7faf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequence dataset shape: (109222, 10, 243) (109222,)\n",
            "Sequence-level positive (fault) rate: 0.4076925894050649\n",
            "Sequence label distribution: {np.int64(0): np.int64(64693), np.int64(1): np.int64(44529)}\n",
            "Train normals: (41403, 10, 243) Val normals: (10351, 10, 243) Test (mixed): (21845, 10, 243)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the CNN + LSTM + Attention Autoencoder for time-series\n",
        "\n",
        "\"\"\"\n",
        "    A hybrid autoencoder combining:\n",
        "      - Gaussian noise (robustness to sensor noise)\n",
        "      - 1D CNN (local trend extraction)\n",
        "      - LSTM encoder (temporal modeling)\n",
        "      - Attention (focus on important timesteps)\n",
        "      - Dense bottleneck (compressed representation)\n",
        "      - LSTM decoder + TimeDistributed Dense (reconstruction)\n",
        "    \"\"\"\n",
        "\n",
        "def build_cnn_lstm_attention_autoencoder(seq_len: int, n_features: int,\n",
        "                                         conv_filters: int = 64,\n",
        "                                         lstm_units: int = 128,\n",
        "                                         dense_units: int = 64,\n",
        "                                         dropout_rate: float = 0.1,\n",
        "                                         gaussian_noise_std: float = 0.01) -> Model:\n",
        "\n",
        "  # input layer\n",
        "  inp = Input(shape=(seq_len, n_features), name='input')\n",
        "\n",
        "  # Add Gaussian Noise\n",
        "  x = GaussianNoise(gaussian_noise_std)(inp)\n",
        "\n",
        "  # 1D Convolution for local pattern extraction\n",
        "  x = Conv1D(filters=conv_filters, kernel_size=2,\n",
        "               activation='relu', padding='same',\n",
        "               name='conv1d')(x)\n",
        "\n",
        "  # Stabilizes learning\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # Downsample by factor 2 (temporal compression)\n",
        "  x = MaxPooling1D(pool_size=2, name='maxpool')(x)\n",
        "\n",
        "  # LSTM Encoder\n",
        "  x = LSTM(units=lstm_units, activation='relu',\n",
        "             return_sequences=True, name='lstm_enc')(x)\n",
        "\n",
        "  # Attention mechanism\n",
        "  att = Attention(name='attention')([x, x])\n",
        "\n",
        "  # Flatten + Dense bottleneck\n",
        "  flat = Flatten(name='flatten')(att)\n",
        "  dense = Dense(dense_units, activation='relu',\n",
        "                name='bottleneck_dense')(flat)\n",
        "\n",
        "  # Mild dropout for regularization\n",
        "  drop = Dropout(dropout_rate)(dense)\n",
        "\n",
        "  # Repeat latent vector to match sequence length\n",
        "  rep = RepeatVector(seq_len)(drop)\n",
        "\n",
        "  # LSTM Decoder\n",
        "  dec = LSTM(units=lstm_units, activation='relu',\n",
        "               return_sequences=True, name='lstm_dec')(rep)\n",
        "\n",
        "  # TimeDistributed Dense layer\n",
        "  out = TimeDistributed(\n",
        "      Dense(n_features, activation='linear'),\n",
        "      name='reconstruction'\n",
        "  )(dec)\n",
        "\n",
        "\n",
        "  # Compile model\n",
        "  model = Model(inp, out, name='cnn_lstm_attention_autoencoder')\n",
        "  model.compile(\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "      loss='mse'   # reconstruction loss\n",
        "  )\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "# Instantiate the model using actual sequence dims\n",
        "seq_len, n_features = X_seq.shape[1], X_seq.shape[2]\n",
        "\n",
        "model = build_cnn_lstm_attention_autoencoder(\n",
        "    seq_len, n_features,\n",
        "    conv_filters=64,\n",
        "    lstm_units=128,\n",
        "    dense_units=64,\n",
        "    dropout_rate=0.1,\n",
        "    gaussian_noise_std=0.01\n",
        ")\n",
        "\n",
        "# Print architecture summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "E79hXARglrX6",
        "outputId": "fb2f1ff6-2ba1-4a4c-8d27-42294c47e7b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"cnn_lstm_attention_autoencoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn_lstm_attention_autoencoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input (\u001b[38;5;33mInputLayer\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m243\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ gaussian_noise      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m243\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mGaussianNoise\u001b[0m)     â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚     \u001b[38;5;34m31,168\u001b[0m â”‚ gaussian_noise[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ maxpool             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_enc (\u001b[38;5;33mLSTM\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚     \u001b[38;5;34m98,816\u001b[0m â”‚ maxpool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lstm_enc[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   â”‚\n",
              "â”‚ (\u001b[38;5;33mAttention\u001b[0m)         â”‚                   â”‚            â”‚ lstm_enc[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ attention[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bottleneck_dense    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚     \u001b[38;5;34m41,024\u001b[0m â”‚ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ bottleneck_denseâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ repeat_vector       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mRepeatVector\u001b[0m)      â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dec (\u001b[38;5;33mLSTM\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚     \u001b[38;5;34m98,816\u001b[0m â”‚ repeat_vector[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reconstruction      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m243\u001b[0m)   â”‚     \u001b[38;5;34m31,347\u001b[0m â”‚ lstm_dec[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
              "â”‚ (\u001b[38;5;33mTimeDistributed\u001b[0m)   â”‚                   â”‚            â”‚                   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">243</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ gaussian_noise      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">243</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GaussianNoise</span>)     â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">31,168</span> â”‚ gaussian_noise[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ maxpool             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_enc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> â”‚ maxpool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ attention           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lstm_enc[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         â”‚                   â”‚            â”‚ lstm_enc[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bottleneck_dense    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> â”‚ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ bottleneck_denseâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ repeat_vector       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RepeatVector</span>)      â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ lstm_dec (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> â”‚ repeat_vector[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ reconstruction      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">243</span>)   â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">31,347</span> â”‚ lstm_dec[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   â”‚                   â”‚            â”‚                   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m301,427\u001b[0m (1.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301,427</span> (1.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301,299\u001b[0m (1.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301,299</span> (1.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING THE AUTOENCODER\n",
        "\n",
        "# Define training hyperparameters\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "\n",
        "#Callbacks to stabilize training\n",
        "callbacks = [\n",
        "    # Stop training early if validation loss does not improve for 8 epochs\n",
        "    EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
        "\n",
        "    # Reduce learning rate when validation loss plateaus\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4,\n",
        "                      min_lr=1e-6, verbose=1),\n",
        "\n",
        "    # Save the best model weights (based on validation loss)\n",
        "    ModelCheckpoint('best_autoencoder.keras', monitor='val_loss',\n",
        "                    save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "\n",
        "# Model Training\n",
        "history = model.fit(\n",
        "    X_train_norm,          # input sequences\n",
        "    X_train_norm,          # target sequences (same as input)\n",
        "    validation_data=(X_val_norm, X_val_norm),   # validation on normal sequences\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "#Plot Training Curve\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='train_loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O1b1C0P1oTE-",
        "outputId": "820beb79-6d65-411a-e8aa-b9f0fe25fe7f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.5399\n",
            "Epoch 1: val_loss improved from inf to 0.34882, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 59ms/step - loss: 0.5393 - val_loss: 0.3488 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m161/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.3488\n",
            "Epoch 2: val_loss improved from 0.34882 to 0.31826, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.3487 - val_loss: 0.3183 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3248\n",
            "Epoch 3: val_loss improved from 0.31826 to 0.29901, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3248 - val_loss: 0.2990 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m158/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.3073\n",
            "Epoch 4: val_loss improved from 0.29901 to 0.28555, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.3071 - val_loss: 0.2856 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m158/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2957\n",
            "Epoch 5: val_loss improved from 0.28555 to 0.27623, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.2956 - val_loss: 0.2762 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m155/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2876\n",
            "Epoch 6: val_loss improved from 0.27623 to 0.26869, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2875 - val_loss: 0.2687 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m161/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2809\n",
            "Epoch 7: val_loss improved from 0.26869 to 0.26071, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2809 - val_loss: 0.2607 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m160/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2742\n",
            "Epoch 8: val_loss improved from 0.26071 to 0.25610, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2742 - val_loss: 0.2561 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m159/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2687\n",
            "Epoch 9: val_loss improved from 0.25610 to 0.24939, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2687 - val_loss: 0.2494 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m160/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2626\n",
            "Epoch 10: val_loss improved from 0.24939 to 0.24336, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2626 - val_loss: 0.2434 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m157/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2583\n",
            "Epoch 11: val_loss improved from 0.24336 to 0.23791, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2583 - val_loss: 0.2379 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2532\n",
            "Epoch 12: val_loss improved from 0.23791 to 0.23345, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.2532 - val_loss: 0.2334 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2491\n",
            "Epoch 13: val_loss improved from 0.23345 to 0.22814, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2491 - val_loss: 0.2281 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2448\n",
            "Epoch 14: val_loss improved from 0.22814 to 0.22475, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2448 - val_loss: 0.2248 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m161/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2414\n",
            "Epoch 15: val_loss improved from 0.22475 to 0.22119, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2413 - val_loss: 0.2212 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m159/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2372\n",
            "Epoch 16: val_loss improved from 0.22119 to 0.21719, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2372 - val_loss: 0.2172 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m156/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2341\n",
            "Epoch 17: val_loss improved from 0.21719 to 0.21182, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2340 - val_loss: 0.2118 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m156/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2302\n",
            "Epoch 18: val_loss improved from 0.21182 to 0.21101, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2301 - val_loss: 0.2110 - learning_rate: 0.0010\n",
            "Epoch 19/50\n",
            "\u001b[1m158/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2277\n",
            "Epoch 19: val_loss improved from 0.21101 to 0.20552, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2277 - val_loss: 0.2055 - learning_rate: 0.0010\n",
            "Epoch 20/50\n",
            "\u001b[1m159/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2240\n",
            "Epoch 20: val_loss improved from 0.20552 to 0.20332, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2240 - val_loss: 0.2033 - learning_rate: 0.0010\n",
            "Epoch 21/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2211\n",
            "Epoch 21: val_loss improved from 0.20332 to 0.20090, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2210 - val_loss: 0.2009 - learning_rate: 0.0010\n",
            "Epoch 22/50\n",
            "\u001b[1m158/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2184\n",
            "Epoch 22: val_loss improved from 0.20090 to 0.19829, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2184 - val_loss: 0.1983 - learning_rate: 0.0010\n",
            "Epoch 23/50\n",
            "\u001b[1m155/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2157\n",
            "Epoch 23: val_loss improved from 0.19829 to 0.19367, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2156 - val_loss: 0.1937 - learning_rate: 0.0010\n",
            "Epoch 24/50\n",
            "\u001b[1m158/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2131\n",
            "Epoch 24: val_loss improved from 0.19367 to 0.19229, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.2131 - val_loss: 0.1923 - learning_rate: 0.0010\n",
            "Epoch 25/50\n",
            "\u001b[1m158/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.2107\n",
            "Epoch 25: val_loss improved from 0.19229 to 0.19008, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.2107 - val_loss: 0.1901 - learning_rate: 0.0010\n",
            "Epoch 26/50\n",
            "\u001b[1m156/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.2091\n",
            "Epoch 26: val_loss did not improve from 0.19008\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.2091 - val_loss: 0.1902 - learning_rate: 0.0010\n",
            "Epoch 27/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2078\n",
            "Epoch 27: val_loss did not improve from 0.19008\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.2078 - val_loss: 0.1901 - learning_rate: 0.0010\n",
            "Epoch 28/50\n",
            "\u001b[1m159/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2066\n",
            "Epoch 28: val_loss improved from 0.19008 to 0.18612, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.2066 - val_loss: 0.1861 - learning_rate: 0.0010\n",
            "Epoch 29/50\n",
            "\u001b[1m155/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2057\n",
            "Epoch 29: val_loss improved from 0.18612 to 0.18513, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.2056 - val_loss: 0.1851 - learning_rate: 0.0010\n",
            "Epoch 30/50\n",
            "\u001b[1m158/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.2040\n",
            "Epoch 30: val_loss improved from 0.18513 to 0.18457, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2040 - val_loss: 0.1846 - learning_rate: 0.0010\n",
            "Epoch 31/50\n",
            "\u001b[1m160/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2028\n",
            "Epoch 31: val_loss improved from 0.18457 to 0.18175, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.2028 - val_loss: 0.1817 - learning_rate: 0.0010\n",
            "Epoch 32/50\n",
            "\u001b[1m161/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.2004\n",
            "Epoch 32: val_loss improved from 0.18175 to 0.17975, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.2004 - val_loss: 0.1798 - learning_rate: 0.0010\n",
            "Epoch 33/50\n",
            "\u001b[1m159/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1979\n",
            "Epoch 33: val_loss improved from 0.17975 to 0.17888, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1979 - val_loss: 0.1789 - learning_rate: 0.0010\n",
            "Epoch 34/50\n",
            "\u001b[1m155/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1972\n",
            "Epoch 34: val_loss improved from 0.17888 to 0.17744, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1972 - val_loss: 0.1774 - learning_rate: 0.0010\n",
            "Epoch 35/50\n",
            "\u001b[1m158/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1957\n",
            "Epoch 35: val_loss improved from 0.17744 to 0.17670, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1957 - val_loss: 0.1767 - learning_rate: 0.0010\n",
            "Epoch 36/50\n",
            "\u001b[1m158/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1942\n",
            "Epoch 36: val_loss improved from 0.17670 to 0.17501, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1942 - val_loss: 0.1750 - learning_rate: 0.0010\n",
            "Epoch 37/50\n",
            "\u001b[1m158/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1935\n",
            "Epoch 37: val_loss did not improve from 0.17501\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1935 - val_loss: 0.1759 - learning_rate: 0.0010\n",
            "Epoch 38/50\n",
            "\u001b[1m157/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.1929\n",
            "Epoch 38: val_loss improved from 0.17501 to 0.17363, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1929 - val_loss: 0.1736 - learning_rate: 0.0010\n",
            "Epoch 39/50\n",
            "\u001b[1m157/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1923\n",
            "Epoch 39: val_loss improved from 0.17363 to 0.17354, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1923 - val_loss: 0.1735 - learning_rate: 0.0010\n",
            "Epoch 40/50\n",
            "\u001b[1m158/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1917\n",
            "Epoch 40: val_loss improved from 0.17354 to 0.17217, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1917 - val_loss: 0.1722 - learning_rate: 0.0010\n",
            "Epoch 41/50\n",
            "\u001b[1m161/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1907\n",
            "Epoch 41: val_loss did not improve from 0.17217\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1907 - val_loss: 0.1735 - learning_rate: 0.0010\n",
            "Epoch 42/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1899\n",
            "Epoch 42: val_loss improved from 0.17217 to 0.17209, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1899 - val_loss: 0.1721 - learning_rate: 0.0010\n",
            "Epoch 43/50\n",
            "\u001b[1m157/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1892\n",
            "Epoch 43: val_loss did not improve from 0.17209\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1892 - val_loss: 0.1723 - learning_rate: 0.0010\n",
            "Epoch 44/50\n",
            "\u001b[1m156/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1886\n",
            "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.17209\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1885 - val_loss: 0.1722 - learning_rate: 0.0010\n",
            "Epoch 45/50\n",
            "\u001b[1m157/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1861\n",
            "Epoch 45: val_loss improved from 0.17209 to 0.16738, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1861 - val_loss: 0.1674 - learning_rate: 5.0000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m159/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1854\n",
            "Epoch 46: val_loss did not improve from 0.16738\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.1854 - val_loss: 0.1675 - learning_rate: 5.0000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m161/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1851\n",
            "Epoch 47: val_loss improved from 0.16738 to 0.16680, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1850 - val_loss: 0.1668 - learning_rate: 5.0000e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m156/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1847\n",
            "Epoch 48: val_loss improved from 0.16680 to 0.16603, saving model to best_autoencoder.keras\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.1847 - val_loss: 0.1660 - learning_rate: 5.0000e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m155/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1843\n",
            "Epoch 49: val_loss did not improve from 0.16603\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1843 - val_loss: 0.1666 - learning_rate: 5.0000e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m156/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.1845\n",
            "Epoch 50: val_loss did not improve from 0.16603\n",
            "\u001b[1m162/162\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.1845 - val_loss: 0.1675 - learning_rate: 5.0000e-04\n",
            "Restoring model weights from the end of the best epoch: 48.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reconstruction Error & Thresholding\n",
        "\n",
        "# Compute per-sequence MSE between true and reconstructed sequences\n",
        "def mse_per_sequence(X_true: np.ndarray, X_pred: np.ndarray) -> np.ndarray:\n",
        "    return np.mean(np.square(X_true - X_pred), axis=(1, 2))\n",
        "\n",
        "\n",
        "\n",
        "# Generate reconstructions for train, validation, and test sets\n",
        "train_recon = model.predict(X_train_norm, verbose=0)\n",
        "val_recon   = model.predict(X_val_mixed, verbose=0)\n",
        "test_recon  = model.predict(X_test, verbose=0)\n",
        "\n",
        "\n",
        "# Compute MSE-based anomaly scores\n",
        "train_mse = mse_per_sequence(X_train_norm, train_recon)\n",
        "val_mse   = mse_per_sequence(X_val_mixed, val_recon)\n",
        "test_mse  = mse_per_sequence(X_test, test_recon)\n",
        "\n",
        "\n",
        "#Unsupervised Threshold\n",
        "\n",
        "thr_unsup = float(np.percentile(train_mse, 99))\n",
        "print(\"Unsupervised (99th percentile) threshold:\", thr_unsup)\n",
        "\n",
        "#Supervised Threshold Tuning (Validation Set)\n",
        "\n",
        "def best_threshold_by_f1(y_true, scores, low_q=0.80, high_q=0.999, n_candidates=200):\n",
        "\n",
        "    # Search threshold values between given quantiles of the score to maximize the F1 score.\n",
        "\n",
        "    thr_candidates = np.quantile(scores, np.linspace(low_q, high_q, n_candidates))\n",
        "\n",
        "    best_f1 = -1.0\n",
        "    best_thr = thr_candidates[0]\n",
        "    best_metrics = None\n",
        "\n",
        "    for t in thr_candidates:\n",
        "        y_pred = (scores > t).astype(int)\n",
        "        p, r, f1, _ = precision_recall_fscore_support(\n",
        "            y_true, y_pred, average='binary', zero_division=0\n",
        "        )\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_thr = t\n",
        "            best_metrics = {'precision': p, 'recall': r, 'f1': f1}\n",
        "\n",
        "    return best_thr, best_metrics\n",
        "\n",
        "\n",
        "# Apply F1-based tuning only when validation contains both classes\n",
        "if len(np.unique(y_val_mixed)) > 1:\n",
        "    thr_f1, f1_metrics = best_threshold_by_f1(y_val_mixed, val_mse)\n",
        "    print(\"F1-tuned threshold:\", thr_f1, \"Val metrics:\", f1_metrics)\n",
        "else:\n",
        "    # If validation has no positives, fallback to unsupervised threshold\n",
        "    thr_f1, f1_metrics = thr_unsup, {'f1': None}\n",
        "    print(\"No positive samples in val_mixed; using unsupervised threshold.\")\n",
        "\n",
        "\n",
        "#Choose Best Threshold (Supervised vs Unsupervised)\n",
        "\n",
        "if f1_metrics['f1'] is not None:\n",
        "    # Compute F1 for unsupervised threshold and compare\n",
        "    y_val_unsup = (val_mse > thr_unsup).astype(int)\n",
        "    p_u, r_u, f1_u, _ = precision_recall_fscore_support(\n",
        "        y_val_mixed, y_val_unsup, average='binary', zero_division=0\n",
        "    )\n",
        "\n",
        "    chosen_thr = thr_f1 if f1_metrics['f1'] >= f1_u else thr_unsup\n",
        "else:\n",
        "    chosen_thr = thr_unsup\n",
        "\n",
        "print(\"Chosen threshold:\", chosen_thr)\n",
        "\n",
        "\n",
        "# Final Test Evaluation\n",
        "\n",
        "# Predict anomalies using chosen threshold\n",
        "y_test_pred = (test_mse > chosen_thr).astype(int)\n",
        "y_test_true = y_test.astype(int)\n",
        "\n",
        "print(\"\\nTest confusion matrix:\")\n",
        "print(confusion_matrix(y_test_true, y_test_pred))\n",
        "\n",
        "print(\"\\nTest classification report:\")\n",
        "print(classification_report(y_test_true, y_test_pred, zero_division=0))\n",
        "\n",
        "# Evaluate how well the MSE anomaly score separates classes\n",
        "try:\n",
        "    auc_score = roc_auc_score(y_test_true, test_mse)\n",
        "    print(\"AUC (anomaly score):\", auc_score)\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpdMOlHorKhk",
        "outputId": "375b3492-f94d-466e-9453-f687f2225ae3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsupervised (99th percentile) threshold: 0.4724752518938516\n",
            "F1-tuned threshold: 0.32275403496277805 Val metrics: {'precision': 0.8755364806866953, 'recall': 0.42947368421052634, 'f1': 0.576271186440678}\n",
            "Chosen threshold: 0.32275403496277805\n",
            "\n",
            "Test confusion matrix:\n",
            "[[12428   511]\n",
            " [ 5099  3807]]\n",
            "\n",
            "Test classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.96      0.82     12939\n",
            "           1       0.88      0.43      0.58      8906\n",
            "\n",
            "    accuracy                           0.74     21845\n",
            "   macro avg       0.80      0.69      0.70     21845\n",
            "weighted avg       0.78      0.74      0.72     21845\n",
            "\n",
            "AUC (anomaly score): 0.7790873539917227\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots\n",
        "# distribution of test MSE\n",
        "plt.figure()\n",
        "sns.histplot(test_mse, bins=50, kde=False)\n",
        "plt.axvline(chosen_thr, color='r', linestyle='--', label=f'Threshold={chosen_thr:.6f}')\n",
        "plt.title(\"Test MSE distribution\")\n",
        "plt.xlabel(\"MSE per sequence\"); plt.legend(); plt.show()\n",
        "\n",
        "# timeline of test MSE (sequence index)\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(test_mse, label='mse')\n",
        "anoms = np.where(test_mse > chosen_thr)[0]\n",
        "plt.scatter(anoms, test_mse[anoms], color='r', label='detected anomaly', s=20)\n",
        "plt.axhline(chosen_thr, color='r', linestyle='--', label='threshold')\n",
        "plt.title('Sequence-level Reconstruction Error (Test set)')\n",
        "plt.xlabel('Sequence index'); plt.ylabel('MSE'); plt.legend(); plt.show()\n",
        "\n",
        "# Save model & artifacts\n",
        "os.makedirs('outputs_wind_fault', exist_ok=True)\n",
        "model.save('outputs_wind_fault/cnn_lstm_attention_autoencoder.keras')\n",
        "np.save('outputs_wind_fault/train_mse.npy', train_mse)\n",
        "np.save('outputs_wind_fault/val_mse.npy', val_mse)\n",
        "np.save('outputs_wind_fault/test_mse.npy', test_mse)\n",
        "pd.DataFrame({'reconstruction_error': test_mse, 'true_class': y_test_true}).to_csv('outputs_wind_fault/test_reconstruction_errors.csv', index=False)\n",
        "with open('outputs_wind_fault/threshold.txt', 'w') as f:\n",
        "    f.write(str(chosen_thr))\n",
        "print(\"Artifacts saved to outputs_wind_fault/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        },
        "id": "hTPss1Hnr7va",
        "outputId": "25fa61b4-73d5-4682-8122-449e9c7a1f8c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artifacts saved to outputs_wind_fault/\n"
          ]
        }
      ]
    }
  ]
}